# 1T_Sprint_4.2

Практика по классическим ML моделям.

Из исходного датасета https://www.kaggle.com/datasets/gauravduttakiit/loan-defaulter было взято 100 тысяч строк выборочно. 
В противном случае, модели обучались крайне долго. Была прозиведена предобработка данных:

1. Удаление столбоцов с пропусками более 50%. Из первоначальных 122 столбцов остался 81 столбец.
2. Заполнение оставшихся пропусков в числовых признаках на медианное значение по столбцу, а в категориальных признаках - на моду.
3. Произведено кодировние категориальных признаков. Из 81 столбца стало 180 столбцов.
4. Далее - разделение на обучающую и тестовую выборки. В фичах 179 столбцов соответственно.
5. Построена матрица важности признаков по отношению к целевому признаку, и удалены наиболее неважные признаки. Из 179 столбцов осталось 23 наиболее значимых столбца.
6. Произведено масштабирование признаков.

Далее:

7. Сделано уменьшение размерности с помощью TSNE (использовалась выборка из 10 тыс.строк). На визуализации четкие кластеры по целевому признаку не выделяются. Perplexity было взято равным 100, так как этот параметр связан с количеством соседей, которые ищутся поблизости. У нас в TARGET всего 2 значения, поэтому кажется, что perplexity стоит взять побольше, чем дефолтное значение равное 30.

Затем:

8. Были обучены четыре модели классификации с предварительным поиском гиперпараметров с помощью RandomizedSearchCV: Логистическая регрессия, Случайный лес и LGBMClassifier.

Все модели на валидационной выборке показали примерно одинаковый скор:

Accuracy = 0.92;

F1 = 0.92 ;

ROC-AUC = 0.737.
