# 1T_Sprint_4.2

Практика по классическим ML моделям.

Из исходного датасета было взято 100 тысяч строк выборочно. В противном случае, модели обучались крайне долго. Была прозиведена предобработка данных:

Удаление столбоцов с пропусками более 50%. Из первоначальных 122 столбцов остался 81 столбец.
Заполнение оставшихся пропусков в числовых признаках на медианное значение по столбцу, а в категориальных признаках - на моду.
Произведено кодировние категориальных признаков. Из 81 столбца стало 180 столбцов.
Далее - разделение на обучающую и тестовую выборки. В фичах 179 столбцов соответственно.
Построена матрица важности признаков по отношению к целевому признаку, и удалены наиболее неважные признаки. Из 179 столбцов осталось 23 наиболее значимых столбца.
Произведено масштабирование признаков.
Далее:

Сделано уменьшение размерности с помощью TSNE (использовалась выборка из 10 тыс.строк). На визуализации четкие кластеры по целевому признаку не выделяются. Perplexity было взято равным 100, так как этот параметр связан с количеством соседей, которые ищутся поблизости. У нас в TARGET всего 2 значения, поэтому кажется, что perplexity стоит взять побольше, чем дефолтное значение равное 30.
Затем:

Были обучены четыре модели классификации с предварительным поиском гиперпараметров с помощью RandomizedSearchCV: Логистическая регрессия, Случайный лес и LGBMClassifier.
Все модели на валидационной выборке

Accuracy = 0.92;

F1 = 0.92 ;

ROC-AUC = 0.737.
